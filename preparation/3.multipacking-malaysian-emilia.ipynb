{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c96b90e1-3c43-455b-8c95-e2f9e7f43930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from transformers import AutoTokenizer, AddedToken\n",
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "import itertools\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield (l[i: i + n], i // n)\n",
    "\n",
    "def multiprocessing(strings, function, cores=6, returned=True):\n",
    "    df_split = chunks(strings, len(strings) // cores)\n",
    "    pool = Pool(cores)\n",
    "    pooled = pool.map(function, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if returned:\n",
    "        return list(itertools.chain(*pooled))\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "    'position_ids': 'uint32',\n",
    "    'attention_mask': 'uint32',\n",
    "    'audio': 'str',\n",
    "    'text': 'str'\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'\n",
    "\n",
    "def new_path(f):\n",
    "    splitted = f.split('/')\n",
    "    base_folder = splitted[0] + '_trim'\n",
    "    splitted = '/'.join([base_folder] + splitted[1:])\n",
    "    return splitted\n",
    "\n",
    "def new_path_neucodec(f):\n",
    "    splitted = f.split('/')\n",
    "    folder = f.split('/')[0]\n",
    "    folder = folder + '_neucodec'\n",
    "    new_f = os.path.join(folder, '/'.join(splitted[1:]))\n",
    "    new_f = new_f.replace('.mp3', '.json').replace('.wav', '.json')\n",
    "    return new_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e1c342e-de1c-4b68-93dd-7123b417be01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36648733a4a841d1ac5d6ac104f18106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/752 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5026b167b75844eda45f5b9adcc74308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00015.parquet:   0%|          | 0.00/44.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d8133958904f41a7cb11d10847722a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00001-of-00015.parquet:   0%|          | 0.00/44.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f2963637264d419cf85a546c27270b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00002-of-00015.parquet:   0%|          | 0.00/44.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a587ca10ef4b288d6dedfbdc7a79d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00003-of-00015.parquet:   0%|          | 0.00/44.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b20a2502934233b8c744860c43da73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00004-of-00015.parquet:   0%|          | 0.00/44.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a10321cbf1141a1b99aa1d42c51d206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00005-of-00015.parquet:   0%|          | 0.00/44.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca77b5879fe47baa8237b77ac8dd69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00006-of-00015.parquet:   0%|          | 0.00/44.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ebcb66d7174ad486229949d520f9a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00007-of-00015.parquet:   0%|          | 0.00/62.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f876fea3c74efcb7e9a53f7f3ab43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00008-of-00015.parquet:   0%|          | 0.00/69.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0d599538cc54302a310fd4939e81df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00009-of-00015.parquet:   0%|          | 0.00/68.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f77585fae114d8aa476188744a841f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00010-of-00015.parquet:   0%|          | 0.00/68.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80864f2997614d77b0074d6208b5a69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00011-of-00015.parquet:   0%|          | 0.00/60.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d1bbc9877e45529b9d80350f9ad86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00012-of-00015.parquet:   0%|          | 0.00/59.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fea385cb58f64e999b1a9d196ae73df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00013-of-00015.parquet:   0%|          | 0.00/57.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475d289ca3c44d17925038fd3166a24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00014-of-00015.parquet:   0%|          | 0.00/57.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6955d37311b4a67a1dd35a3d9da51bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8664602 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Scicom-intl/Malaysian-Emilia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b93ac400-d1f8-49b0-b62f-787a2c190915",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = ds['train'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867f3116-cb11-4349-a08d-240ffe55e891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8664602"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2abeecd-057f-4418-954c-35fc2866f84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8664602/8664602 [00:03<00:00, 2390703.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1414505"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = set()\n",
    "for r in tqdm(rows):\n",
    "    if 'malaysian-chinese' in r['reference_audio'].split('/')[0]:\n",
    "        continue\n",
    "    files.add(r['reference_audio'])\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fbd117e-7b1c-4a0f-bc2f-51fd65738c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 8664602/8664602 [00:24<00:00, 360866.62it/s]\n"
     ]
    }
   ],
   "source": [
    "not_exists = []\n",
    "for r in tqdm(rows):\n",
    "    if 'malaysian-chinese' in r['reference_audio'].split('/')[0]:\n",
    "        continue\n",
    "    f = new_path_neucodec(new_path(r['reference_audio']))\n",
    "    if not os.path.exists(f):\n",
    "        not_exists.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "241f03e6-e461-4422-a27b-288712f93d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = new_path_neucodec(new_path(rows[0]['reference_audio']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31bf0c93-e958-40f7-b342-821e489a2dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65537"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-1.7B-Base')\n",
    "extra = [AddedToken('<|speech_start|>')]\n",
    "for i in range(65536):\n",
    "    extra.append(AddedToken(f'<|s_{i}|>'))\n",
    "tokenizer.add_tokens(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ea63ad-bc36-485e-8d3f-66ad56f9502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def collator(batch, batch_position_ids):\n",
    "    input_ids = []\n",
    "    position_ids = []\n",
    "    masks = []\n",
    "    for i in range(len(batch)):\n",
    "        l = len(batch[i])\n",
    "        input_ids.extend(batch[i])\n",
    "        position_ids.extend(batch_position_ids[i])\n",
    "        masks.append(l)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': np.array(input_ids).astype(np.uint32),\n",
    "        'position_ids': np.array(position_ids).astype(np.uint32),\n",
    "        'attention_mask': np.array(masks).astype(np.uint32),\n",
    "        'audio': '',\n",
    "        'text': '',\n",
    "    }\n",
    "\n",
    "def slice_and_balance(nested_list, size):\n",
    "    first = []\n",
    "    balance = []\n",
    "    current_size = 0\n",
    "\n",
    "    for sublist in nested_list:\n",
    "        if current_size < size:\n",
    "            remaining_space = size - current_size\n",
    "            if len(sublist) <= remaining_space:\n",
    "                first.append(sublist)\n",
    "                current_size += len(sublist)\n",
    "            else:\n",
    "                first.append(sublist[:remaining_space])\n",
    "                balance.append(sublist[remaining_space:])\n",
    "                current_size = size\n",
    "        else:\n",
    "            balance.append(sublist)\n",
    "    \n",
    "    return first, balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b488f43-60a6-4353-8f37-01fd89cd8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "sequence_length = 1024 * 10\n",
    "def loop(files, block_size = sequence_length):\n",
    "    rows, index = files\n",
    "    out_root = f'malaysian-emilia/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    count = 0\n",
    "    temp = []\n",
    "    position_ids = []\n",
    "    last_block, last_position_block = None, None\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for row in tqdm(rows):\n",
    "\n",
    "            if 'malaysian-chinese' in row['reference_audio'].split('/')[0]:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                with open(new_path_neucodec(new_path(row['reference_audio']))) as fopen:\n",
    "                    left = json.load(fopen)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                with open(new_path_neucodec(new_path(row['target_audio']))) as fopen:\n",
    "                    right = json.load(fopen)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            left_text = row['reference_text']\n",
    "            right_text = row['target_text']\n",
    "\n",
    "            if len(left_text.split()) > len(left):\n",
    "                continue\n",
    "\n",
    "            if len(right_text.split()) > len(right):\n",
    "                continue\n",
    "            \n",
    "            left_token = ''.join([f'<|s_{t}|>' for t in left])\n",
    "            right_token = ''.join([f'<|s_{t}|>' for t in right])\n",
    "            \n",
    "            left_prompt = f'<|im_start|>{left_text}<|speech_start|>{left_token}<|im_end|>'\n",
    "            right_prompt = f'<|im_start|>{right_text}<|speech_start|>{right_token}<|im_end|>'\n",
    "\n",
    "            prompt = left_prompt + right_prompt\n",
    "            \n",
    "            outputs = tokenizer(prompt, add_special_tokens = False)\n",
    "            position = range(len(outputs['input_ids']))\n",
    "            length = len(outputs['input_ids'])\n",
    "            \n",
    "            if count + length > block_size:\n",
    "                o = collator(temp, position_ids)\n",
    "                if o['input_ids'].shape[0] > 0:\n",
    "                    out.write(o)\n",
    "                temp = [outputs['input_ids']]\n",
    "                position_ids = [position]\n",
    "                count = length\n",
    "                \n",
    "            else:\n",
    "                temp.append(outputs['input_ids'])\n",
    "                position_ids.append(range(len(outputs['input_ids'])))\n",
    "                count += len(outputs['input_ids'])\n",
    "        \n",
    "        if len(temp):\n",
    "            o = collator(temp, position_ids)\n",
    "            if o['input_ids'].shape[0] > 0:\n",
    "                out.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8034e74-f9fe-43da-bbdb-0a1a04378527",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3426690.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3044664.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3058171.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 2898906.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3058006.97it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3109776.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3577514.50it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3065818.43it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 216615/216615 [00:00<00:00, 3056330.18it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 53.72it/s]\n",
      " 65%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                                    | 140854/216615 [08:11<04:36, 273.70it/s]"
     ]
    }
   ],
   "source": [
    "multiprocessing(rows, loop, cores = 40, returned = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5563c5-69f6-410e-a91c-80e54c8cdbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = sorted(glob('malaysian-emilia/tokenized-*'), key = lambda x: int(x.split('-')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d7ce7-457c-44c4-bd28-732cfb9e05ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf multipacking-malaysian-emilia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312004fb-67b2-4840-aa6e-491ecd3b9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MDSWriter(out='multipacking-malaysian-emilia', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for f in folders:\n",
    "        try:\n",
    "            dataset = LocalDataset(local=f)\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                out.write(dataset[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f5b6c-1edf-46e9-a95d-fd32a692fb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalDataset('multipacking-malaysian-emilia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50a16d37-752f-47e3-aaa5-dc50a03a0c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58G\tmultipacking-malaysian-emilia\n"
     ]
    }
   ],
   "source": [
    "!du -hs multipacking-malaysian-emilia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35465f0d-2c34-4699-b065-731d78a652a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797570"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2543a-c0f7-4aa9-844b-0d4f5768aad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems you are trying to upload a large folder at once. This might take some time and then fail if the folder is too large. For such cases, it is recommended to upload in smaller batches or to use `HfApi().upload_large_folder(...)`/`hf upload-large-folder` instead. For more details, check out https://huggingface.co/docs/huggingface_hub/main/en/guides/upload#upload-a-large-folder.\n",
      "Start hashing 915 files.\n"
     ]
    }
   ],
   "source": [
    "!hf upload Scicom-intl/Malaysian-Emilia-multipacking-10k multipacking-malaysian-emilia --repo-type=dataset --private"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaysian-reasoning",
   "language": "python",
   "name": "malaysian-reasoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
