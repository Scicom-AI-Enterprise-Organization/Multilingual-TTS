{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "122cc757-0d20-463c-a5ce-82bb0a0e8410",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "import io\n",
    "import json\n",
    "import gc\n",
    "import yaml\n",
    "import tempfile\n",
    "import requests\n",
    "import soundfile as sf\n",
    "from multiprocessing import Pool\n",
    "from huggingface_hub import hf_hub_download\n",
    "from datasets import Dataset, Features, Value, load_dataset\n",
    "from huggingface_hub import hf_hub_download, get_token\n",
    "from tqdm import tqdm\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a89bc8e-5491-445a-ac61-f06332e6d0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 0.84ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de10501-3a51-4159-b86a-18546f1ba9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\n",
      "Collecting rapidfuzz>=3.9.7\n",
      "  Downloading rapidfuzz-3.14.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m99.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.2.1)\n",
      "Installing collected packages: rapidfuzz, jiwer\n",
      "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63a998de-433f-4d48-a333-97969d1765f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import get_token\n",
    "\n",
    "token = get_token() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e2e575d-7b69-4adb-a89b-65c610154fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_langs = \"- en   - zh   - de   - es   - ru   - ko   - fr   - ja   - pt   - tr   - pl   - ca   - nl   - ar   - sv   - it   - id   - hi   - fi   - vi   - he   - uk   - el   - ms   - cs   - ro   - da   - hu   - ta   - 'no'   - th   - ur   - hr   - bg   - lt   - la   - mi   - ml   - cy   - sk   - te   - fa   - lv   - bn   - sr   - az   - sl   - kn   - et   - mk   - br   - eu   - is   - hy   - ne   - mn   - bs   - kk   - sq   - sw   - gl   - mr   - pa   - si   - km   - sn   - yo   - so   - af   - oc   - ka   - be   - tg   - sd   - gu   - am   - yi   - lo   - uz   - fo   - ht   - ps   - tk   - nn   - mt   - sa   - lb   - my   - bo   - tl   - mg   - as   - tt   - haw   - ln   - ha   - ba   - jw   - su\"\n",
    "\n",
    "list2 = re.findall(r\"[a-z]+(?:-[a-zA-Z]+)*\", raw_langs)\n",
    "whisper_supported = [lang.replace(\"'\", \"\") for lang in list2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "286e7b57-743b-45ea-b841-11ef5c62287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(code):\n",
    "    return code.split(\"-\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad652bbf-e649-46df-a56d-45befcb912f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file_path = hf_hub_download(\n",
    "    repo_id=\"sarulab-speech/commonvoice22_sidon\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"paths.yaml\"\n",
    ")\n",
    "\n",
    "\n",
    "paths = yaml.load(open(data_file_path, \"r\"), Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adad7557-61ba-46b9-9de9-2231baccb9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Languages compatible ['af', 'am', 'ar', 'as', 'az', 'ba', 'be', 'bg', 'bn', 'br', 'ca', 'cs', 'cy', 'da', 'de', 'el', 'en', 'es', 'et', 'eu', 'fa', 'fi', 'fr', 'gl', 'ha', 'he', 'hi', 'ht', 'hu', 'hy-AM', 'id', 'is', 'it', 'ja', 'ka', 'kk', 'ko', 'lo', 'lt', 'lv', 'mk', 'ml', 'mn', 'mr', 'mt', 'ne-NP', 'nl', 'nn-NO', 'oc', 'pa-IN', 'pl', 'ps', 'pt', 'ro', 'ru', 'sd', 'sk', 'sl', 'sq', 'sr', 'sv-SE', 'sw', 'ta', 'te', 'tg', 'th', 'tk', 'tr', 'tt', 'uk', 'ur', 'uz', 'vi', 'yi', 'yo', 'zh-CN', 'zh-HK', 'zh-TW']\n",
      "Total: 78\n"
     ]
    }
   ],
   "source": [
    "valid_languages = []\n",
    "\n",
    "for lang in paths.keys():\n",
    "    base_lang = normalize(lang)\n",
    "    if base_lang in whisper_supported and \"test\" in paths[lang]:\n",
    "        valid_languages.append(lang)\n",
    "print(\"Languages compatible\", valid_languages)\n",
    "print(\"Total:\", len(valid_languages))\n",
    "\n",
    "valid_lang_file = \"valid_languages.json\"\n",
    "with open(valid_lang_file, \"w\") as f:\n",
    "    json.dump(valid_languages, f, indent=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f816ef58-8b4d-40c0-9d8d-157676bce77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 131/131 [00:00<00:00, 36591.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "af: 131 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 252/252 [00:00<00:00, 71214.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "am: 252 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 379/379 [00:00<00:00, 107032.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as: 379 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 95/95 [00:00<00:00, 29585.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "az: 95 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 156282.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bg: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 152965.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ar: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 160246.96 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "br: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 152188.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ba: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 144253.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bn: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 161431.14 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 154157.01 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "da: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 135931.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cs: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 170126.71 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cy: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 154588.83 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 132454.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 163393.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 157668.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 159140.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 163571.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 159007.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fi: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 154395.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 152398.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ha: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 392/392 [00:00<00:00, 122570.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he: 392 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 160357.24 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 1593.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ht: 5 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 156293.93 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 139772.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gl: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 137302.08 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:00<00:00, 2997.83 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is: 9 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 159795.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hy-AM: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 159321.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 162167.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ja: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 163177.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kk: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 151692.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hu: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 472/472 [00:00<00:00, 148049.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ko: 472 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 26/26 [00:00<00:00, 8897.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lo: 26 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 146766.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ka: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 166150.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mk: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 160504.52 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lt: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 166625.77 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 154009.84 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 153412.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lv: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 164831.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mn: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 287/287 [00:00<00:00, 96239.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ne-NP: 287 rows saved"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mr pass2 test-00000.tar.gz: 272it [00:02, 105.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 166811.33 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mr: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 423/423 [00:00<00:00, 133297.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn-NO: 423 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 146592.48 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mt: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 274/274 [00:00<00:00, 89861.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oc: 274 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 163329.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pa-IN: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 138553.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 135160.61 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ro: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 159783.01 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nl: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 143023.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pt: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 40/40 [00:00<00:00, 13523.47 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sd: 40 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 151091.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 165769.66 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sl: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 137934.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sq: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 163113.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 150506.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sr: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 152809.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sv-SE: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 20525.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "te: 66 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 153862.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ru: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 22190.38 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tg: 69 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 141479.59 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tk: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 152177.06 examples/s]\n",
      "                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sw: 500 rows saved"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 138343.69 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 156562.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ta: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 154327.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 152853.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 3890.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ur: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 108818.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vi: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 222/222 [00:00<00:00, 68779.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yi: 222 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 160492.23 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 147759.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uk: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 162054.86 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh-TW: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 152486.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uz: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 155356.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh-HK: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 165612.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zh-CN: 500 rows saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overall: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 78/78 [13:41<00:00, 10.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zipping audio files...\n",
      "Done. Upload vc_audio.zip to your storage.\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "import requests\n",
    "import soundfile as sf\n",
    "import yaml\n",
    "from datasets import Dataset, Features, Value\n",
    "from huggingface_hub import hf_hub_download\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "from huggingface_hub import get_token\n",
    "\n",
    "HF_TOKEN = get_token()\n",
    "MAX_ROWS = 500\n",
    "SPLIT = \"test\"\n",
    "SAVE_DIR = \"vc_dataset\"\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "with open(\"valid_languages.json\") as f:\n",
    "    valid_languages = json.load(f)\n",
    "\n",
    "paths_file = hf_hub_download(\n",
    "    repo_id=\"sarulab-speech/commonvoice22_sidon\",\n",
    "    repo_type=\"dataset\",\n",
    "    filename=\"paths.yaml\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "paths = yaml.safe_load(open(paths_file))\n",
    "\n",
    "base_url = \"https://huggingface.co/datasets/sarulab-speech/commonvoice22_sidon/resolve/main/\"\n",
    "\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "metadata_features = Features({\n",
    "    \"flac\": Value(\"binary\"),\n",
    "    \"metadata.json\": {\n",
    "        \"accent\": Value(\"string\"),\n",
    "        \"age\": Value(\"string\"),\n",
    "        \"client_id\": Value(\"string\"),\n",
    "        \"down_votes\": Value(\"int64\"),\n",
    "        \"gender\": Value(\"string\"),\n",
    "        \"id\": Value(\"string\"),\n",
    "        \"locale\": Value(\"string\"),\n",
    "        \"path\": Value(\"string\"),\n",
    "        \"segment\": Value(\"string\"),\n",
    "        \"sentence\": Value(\"string\"),\n",
    "        \"up_votes\": Value(\"int64\"),\n",
    "        \"variant\": Value(\"string\"),\n",
    "    },\n",
    "    \"__key__\": Value(\"string\"),\n",
    "    \"__url__\": Value(\"string\"),\n",
    "})\n",
    "\n",
    "\n",
    "def download_shard(url, dest_path):\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(dest_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=8 * 1024 * 1024):\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "def process_lang(lang):\n",
    "    from datasets import load_dataset  # import inside worker to avoid multiprocessing issues\n",
    "\n",
    "    save_path = os.path.join(SAVE_DIR, lang)\n",
    "    if os.path.exists(save_path):\n",
    "        print(f\"{lang}: already saved, skipping\")\n",
    "        return\n",
    "\n",
    "    if lang not in paths or SPLIT not in paths[lang]:\n",
    "        print(f\"{lang}: no test split, skipping\")\n",
    "        return\n",
    "\n",
    "    shard_paths = paths[lang][SPLIT]\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    for shard_rel_path in shard_paths:\n",
    "        url = base_url + shard_rel_path\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\", delete=False) as tmp:\n",
    "            tmp_path = tmp.name\n",
    "\n",
    "        try:\n",
    "            download_shard(url, tmp_path)\n",
    "\n",
    "            ds = load_dataset(\n",
    "                \"webdataset\",\n",
    "                data_files=[tmp_path],\n",
    "                streaming=True,\n",
    "                features=metadata_features,\n",
    "            )[\"train\"]\n",
    "\n",
    "            for sample in tqdm(ds, desc=f\"{lang} pass1 {os.path.basename(shard_rel_path)}\", leave=False):\n",
    "                meta = sample.get(\"metadata.json\", {})\n",
    "                sentence = meta.get(\"sentence\", \"\")\n",
    "                key = sample.get(\"__key__\")\n",
    "\n",
    "                if not sentence:\n",
    "                    continue\n",
    "\n",
    "                all_rows.append({\n",
    "                    \"key\": key,\n",
    "                    \"language\": lang,\n",
    "                    \"source_text\": sentence,\n",
    "                    \"upvotes\": int(meta.get(\"up_votes\", 0)),\n",
    "                    \"speaker_id\": meta.get(\"client_id\", \"\"),\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{lang}: pass1 shard {shard_rel_path} failed - {e}\")\n",
    "        finally:\n",
    "            os.remove(tmp_path)\n",
    "\n",
    "    if not all_rows:\n",
    "        print(f\"{lang}: no rows found\")\n",
    "        return\n",
    "\n",
    "    all_rows.sort(key=lambda x: x[\"upvotes\"], reverse=True)\n",
    "    top_rows = all_rows[:MAX_ROWS]\n",
    "    top_keys = set(r[\"key\"] for r in top_rows)\n",
    "\n",
    "    del all_rows\n",
    "    gc.collect()\n",
    "\n",
    "    # PASS 2: download audio and save as flac files\n",
    "    audio_dir = os.path.join(save_path, \"audio\")\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "    audio_map = {}\n",
    "\n",
    "    for shard_rel_path in shard_paths:\n",
    "        if len(audio_map) == len(top_keys):\n",
    "            break\n",
    "\n",
    "        url = base_url + shard_rel_path\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".tar.gz\", delete=False) as tmp:\n",
    "            tmp_path = tmp.name\n",
    "\n",
    "        try:\n",
    "            download_shard(url, tmp_path)\n",
    "\n",
    "            ds = load_dataset(\n",
    "                \"webdataset\",\n",
    "                data_files=[tmp_path],\n",
    "                streaming=True,\n",
    "                features=metadata_features,\n",
    "            )[\"train\"]\n",
    "\n",
    "            for sample in tqdm(ds, desc=f\"{lang} pass2 {os.path.basename(shard_rel_path)}\", leave=False):\n",
    "                key = sample.get(\"__key__\")\n",
    "                if key in top_keys:\n",
    "                    flac_bytes = sample.get(\"flac\")\n",
    "                    try:\n",
    "                        array, sampling_rate = sf.read(io.BytesIO(flac_bytes))\n",
    "                        audio_filename = f\"{key}.flac\"\n",
    "                        audio_path = os.path.join(audio_dir, audio_filename)\n",
    "                        sf.write(audio_path, array, sampling_rate)\n",
    "                        audio_map[key] = audio_filename\n",
    "                    except Exception as e:\n",
    "                        print(f\"{lang}: audio decode failed for {key} - {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{lang}: pass2 shard {shard_rel_path} failed - {e}\")\n",
    "        finally:\n",
    "            os.remove(tmp_path)\n",
    "\n",
    "    # assign target_text from a different row\n",
    "    texts = [r[\"source_text\"] for r in top_rows]\n",
    "    for i, row in enumerate(top_rows):\n",
    "        for offset in range(1, len(texts)):\n",
    "            candidate = texts[(i + offset) % len(texts)]\n",
    "            if candidate != row[\"source_text\"]:\n",
    "                row[\"target_text\"] = candidate\n",
    "                break\n",
    "        else:\n",
    "            row[\"target_text\"] = texts[(i + 1) % len(texts)]\n",
    "\n",
    "    final_rows = [{\n",
    "        \"language\": r[\"language\"],\n",
    "        \"source_text\": r[\"source_text\"],\n",
    "        \"target_text\": r[\"target_text\"],\n",
    "        \"upvotes\": r[\"upvotes\"],\n",
    "        \"speaker_id\": r[\"speaker_id\"],\n",
    "        \"audio_filename\": audio_map.get(r[\"key\"], \"\"),\n",
    "    } for r in top_rows]\n",
    "\n",
    "    dataset = Dataset.from_list(final_rows)\n",
    "    dataset.save_to_disk(save_path)\n",
    "    print(f\"{lang}: {len(final_rows)} rows saved\")\n",
    "\n",
    "    del top_rows, final_rows, dataset, audio_map\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "with Pool(NUM_WORKERS) as pool:\n",
    "    list(tqdm(\n",
    "        pool.imap(process_lang, valid_languages),\n",
    "        total=len(valid_languages),\n",
    "        desc=\"Overall\",\n",
    "    ))\n",
    "\n",
    "# Zip all audio files for easy upload\n",
    "print(\"Zipping audio files...\")\n",
    "shutil.make_archive(\"vc_audio\", \"zip\", SAVE_DIR)\n",
    "print(\"Done. Upload vc_audio.zip to your storage.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8308c21-d806-4115-804a-36ee8dc84253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Push!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83bbf7e-caa0-4a0d-b4d7-7b111d9187aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "\n",
    "REPO_ID = \"Scicom-intl/Evaluation_Multilingual_VC\"\n",
    "SAVE_DIR = \"vc_dataset2\"\n",
    "HF_TOKEN = \"\"\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "api.create_repo(repo_id=REPO_ID, repo_type=\"dataset\", token=HF_TOKEN, exist_ok=True)\n",
    "\n",
    "\n",
    "for lang in os.listdir(SAVE_DIR):\n",
    "    lang_path = os.path.join(SAVE_DIR, lang)\n",
    "    if not os.path.isdir(lang_path):\n",
    "        continue\n",
    "    try:\n",
    "        ds = load_from_disk(lang_path)\n",
    "        ds.push_to_hub(\n",
    "            REPO_ID,\n",
    "            config_name=lang,\n",
    "            token=HF_TOKEN,\n",
    "            private=True,\n",
    "        )\n",
    "        print(f\"Pushed {lang} — {len(ds)} rows\")\n",
    "    except Exception as e:\n",
    "        print(f\" Failed {lang}: {e}\")\n",
    "\n",
    "api.upload_file(\n",
    "    path_or_fileobj=\"vc_audio.zip\",\n",
    "    path_in_repo=\"vc_audio.zip\",\n",
    "    repo_id=REPO_ID,\n",
    "    repo_type=\"dataset\",\n",
    "    token=HF_TOKEN,\n",
    ")\n",
    "print(\" Audio zip uploaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27005bf7-021d-4071-95b2-f4940c568ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check whisper language support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c73504f-a3f8-4ae2-bc65-0cae3a859203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import soundfile as sf\n",
    "import os\n",
    "import json\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from jiwer import cer\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "supported = []\n",
    "unsupported = []\n",
    "results = {}\n",
    "\n",
    "for lang in os.listdir(\"vc_dataset2\"):\n",
    "    lang_path = os.path.join(\"vc_dataset2\", lang)\n",
    "    if not os.path.isdir(lang_path):\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        ds = load_from_disk(lang_path)\n",
    "        \n",
    "        # Take first 5 rows\n",
    "        sample_rows = [ds[i] for i in range(min(5, len(ds)))]\n",
    "        \n",
    "        cer_scores = []\n",
    "        row_results = []\n",
    "\n",
    "        for row in sample_rows:\n",
    "            audio_path = os.path.join(lang_path, \"audio\", row[\"audio_filename\"])\n",
    "            result = pipe(audio_path)\n",
    "            transcription = result[\"text\"].strip()\n",
    "            source = row[\"source_text\"]\n",
    "            score = cer(source, transcription)\n",
    "            cer_scores.append(score)\n",
    "            row_results.append({\n",
    "                \"expected\": source,\n",
    "                \"got\": transcription,\n",
    "                \"cer\": round(score, 4),\n",
    "            })\n",
    "\n",
    "        avg_cer = sum(cer_scores) / len(cer_scores)\n",
    "        supported_flag = avg_cer < 0.8\n",
    "\n",
    "        print(f\"\\n{'wowww' if supported_flag else 'baddd'} {lang} avg CER: {avg_cer:.2f}\")\n",
    "        for r in row_results:\n",
    "            print(f\"   Expected : {r['expected']}\")\n",
    "            print(f\"   Got      : {r['got']}\")\n",
    "            print(f\"   CER      : {r['cer']}\")\n",
    "\n",
    "        if supported_flag:\n",
    "            supported.append(lang)\n",
    "        else:\n",
    "            unsupported.append(lang)\n",
    "\n",
    "        results[lang] = {\n",
    "            \"supported\": supported_flag,\n",
    "            \"avg_cer\": round(avg_cer, 4),\n",
    "            \"samples\": row_results,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\" {lang}: {e}\")\n",
    "        unsupported.append(lang)\n",
    "        results[lang] = {\n",
    "            \"supported\": False,\n",
    "            \"error\": str(e),\n",
    "        }\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"whisper_language_support.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"supported\": supported,\n",
    "        \"unsupported\": unsupported,\n",
    "        \"details\": results,\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\nSupported: {len(supported)} — {supported}\")\n",
    "print(f\"\\nUnsupported: {len(unsupported)} — {unsupported}\")\n",
    "print(\"\\nSaved to whisper_language_support.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
